{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook archives the code to process the full data set and save the encoded faces in `/data_processed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mmcv, cv2\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageEnhance\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.2.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading parameters (1/2)\n",
      "Downloading parameters (2/2)\n"
     ]
    }
   ],
   "source": [
    "# Load face detector\n",
    "mtcnn = MTCNN(margin=14, keep_all=True, post_process=False, thresholds = [0.9, 0.9, 0.9], device=device).eval()\n",
    "\n",
    "# Load facial recognition model, but I didn't want to use it yet\n",
    "resnet = InceptionResnetV1(pretrained='vggface2', device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionPipeline:\n",
    "    \"\"\"Pipeline class for detecting faces in the frames of a video file.\"\"\"\n",
    "    \n",
    "    def __init__(self, detector, n_frames=None, batch_size=60, resize=None):\n",
    "        \"\"\"Constructor for DetectionPipeline class.\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            n_frames {int} -- Total number of frames to load. These will be evenly spaced\n",
    "                throughout the video. If not specified (i.e., None), all frames will be loaded.\n",
    "                (default: {None})\n",
    "            batch_size {int} -- Batch size to use with MTCNN face detector. (default: {32})\n",
    "            resize {float} -- Fraction by which to resize frames from original prior to face\n",
    "                detection. A value less than 1 results in downsampling and a value greater than\n",
    "                1 result in upsampling. (default: {None})\n",
    "        \"\"\"\n",
    "        self.detector = detector\n",
    "        self.n_frames = n_frames\n",
    "        self.batch_size = batch_size\n",
    "        self.resize = resize\n",
    "    \n",
    "    def __call__(self, filename):\n",
    "        \"\"\"Load frames from an MP4 video and detect faces.\n",
    "\n",
    "        Arguments:\n",
    "            filename {str} -- Path to video.\n",
    "        \"\"\"\n",
    "        # Create video reader and find length\n",
    "        v_cap = cv2.VideoCapture(filename)\n",
    "        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Pick 'n_frames' evenly spaced frames to sample\n",
    "        if self.n_frames is None:\n",
    "            sample = np.arange(1, v_len)\n",
    "        else:\n",
    "            sample = np.linspace(1, v_len - 1, self.n_frames).astype(int)\n",
    "\n",
    "        # Loop through frames\n",
    "        faces = []\n",
    "        frames = []\n",
    "        for j in range(v_len):\n",
    "            success = v_cap.grab()\n",
    "            if j in sample:\n",
    "                # Load frame\n",
    "                success, frame = v_cap.retrieve()\n",
    "                if not success:\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                max_p = frame.max()\n",
    "                frame = Image.fromarray(frame)\n",
    "                if max_p < 150:\n",
    "                    enhancer = ImageEnhance.Brightness(frame)\n",
    "                    frame = enhancer.enhance(255/max_p)\n",
    "                    \n",
    "                # Resize frame to desired size\n",
    "                if self.resize is not None:\n",
    "                    frame = frame.resize([int(d * self.resize) for d in frame.size])\n",
    "                \n",
    "                frames.append(frame)\n",
    "\n",
    "                # When batch is full, detect faces and reset frame list\n",
    "                if len(frames) % self.batch_size == 0 or j == sample[-1]:\n",
    "                    faces.extend(self.detector(frames))\n",
    "                    frames = []\n",
    "\n",
    "        v_cap.release()\n",
    "\n",
    "        return faces    \n",
    "\n",
    "\n",
    "def process_faces(faces, resnet):\n",
    "    # Filter out frames without faces\n",
    "    faces = [f for f in faces if f is not None]\n",
    "    faces = torch.cat(faces).to(device)\n",
    "\n",
    "    # Generate facial feature vectors using a pretrained model\n",
    "    embeddings = resnet(faces)\n",
    "\n",
    "    # Calculate centroid for video and distance of each face's feature vector from centroid\n",
    "#     centroid = embeddings.mean(dim=0)\n",
    "#     x = (embeddings - centroid).norm(dim=1).cpu().numpy()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Videos for speed test\n",
    "    \n",
    "* I see 400 videos took minutes 18 minutes on a pair of P100s. There are 292/400 videos with 1 face only, 16 with 2 faces and none with three in every frame. The same dataset took about 13 minutes on a pair of V100s, given the prices differences I will use P100s to process the entire thing. \n",
    "    \n",
    "* An estimate of ETA is 2000 videos/folder * 50 folders * 18 minute/400videos = 4500 minutes or 75 hours. \n",
    "    \n",
    "* However, I noticed that MTCNN only uses one GPU. Therefore I duplicated this workbook so that we have both GPUs running at the same time. Ideally it should half the time and we are looking at 1 day and half. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/400 [00:02<19:38,  2.95s/it]\u001b[A\n",
      "  0%|          | 2/400 [00:06<19:50,  2.99s/it]\u001b[A\n",
      "  1%|          | 3/400 [00:09<19:50,  3.00s/it]\u001b[A\n",
      "  1%|          | 4/400 [00:12<21:20,  3.23s/it]\u001b[A\n",
      "  1%|▏         | 5/400 [00:15<20:19,  3.09s/it]\u001b[A\n",
      "  2%|▏         | 6/400 [00:18<19:50,  3.02s/it]\u001b[A\n",
      "  2%|▏         | 7/400 [00:22<21:03,  3.22s/it]\u001b[A\n",
      "  2%|▏         | 8/400 [00:24<20:07,  3.08s/it]\u001b[A\n",
      "  2%|▏         | 9/400 [00:28<21:44,  3.34s/it]\u001b[A\n",
      "  2%|▎         | 10/400 [00:31<21:07,  3.25s/it]\u001b[A\n",
      "  3%|▎         | 11/400 [00:35<21:58,  3.39s/it]\u001b[A\n",
      "  3%|▎         | 12/400 [00:38<21:33,  3.33s/it]\u001b[A\n",
      "  3%|▎         | 13/400 [00:41<20:51,  3.23s/it]\u001b[A\n",
      "  4%|▎         | 14/400 [00:45<22:20,  3.47s/it]\u001b[A\n",
      "  4%|▍         | 15/400 [00:49<21:53,  3.41s/it]\u001b[A\n",
      "  4%|▍         | 16/400 [00:52<21:20,  3.33s/it]\u001b[A\n",
      "  4%|▍         | 17/400 [00:55<20:21,  3.19s/it]\u001b[A\n",
      "  4%|▍         | 18/400 [00:58<20:26,  3.21s/it]\u001b[A\n",
      "  5%|▍         | 19/400 [01:01<20:14,  3.19s/it]\u001b[A\n",
      "  5%|▌         | 20/400 [01:04<19:43,  3.11s/it]\u001b[A\n",
      "  5%|▌         | 21/400 [01:07<19:31,  3.09s/it]\u001b[A\n",
      "  6%|▌         | 22/400 [01:10<20:17,  3.22s/it]\u001b[A\n",
      "  6%|▌         | 23/400 [01:13<19:51,  3.16s/it]\u001b[A\n",
      "  6%|▌         | 24/400 [01:17<19:52,  3.17s/it]\u001b[A\n",
      "  6%|▋         | 25/400 [01:20<20:43,  3.31s/it]\u001b[A\n",
      "  6%|▋         | 26/400 [01:23<19:43,  3.16s/it]\u001b[A\n",
      "  7%|▋         | 27/400 [01:26<19:16,  3.10s/it]\u001b[A\n",
      "  7%|▋         | 28/400 [01:30<20:40,  3.33s/it]\u001b[A\n",
      "  7%|▋         | 29/400 [01:33<19:30,  3.16s/it]\u001b[A\n",
      "  8%|▊         | 30/400 [01:36<19:41,  3.19s/it]\u001b[A\n",
      "  8%|▊         | 31/400 [01:39<19:16,  3.13s/it]\u001b[A\n",
      "  8%|▊         | 32/400 [01:43<20:26,  3.33s/it]\u001b[A\n",
      "  8%|▊         | 33/400 [01:46<19:49,  3.24s/it]\u001b[A\n",
      "  8%|▊         | 34/400 [01:49<19:06,  3.13s/it]\u001b[A\n",
      "  9%|▉         | 35/400 [01:53<20:40,  3.40s/it]\u001b[A\n",
      "  9%|▉         | 36/400 [01:57<21:23,  3.53s/it]\u001b[A\n",
      "  9%|▉         | 37/400 [02:00<20:26,  3.38s/it]\u001b[A\n",
      " 10%|▉         | 38/400 [02:02<19:31,  3.24s/it]\u001b[A\n",
      " 10%|▉         | 39/400 [02:06<19:05,  3.17s/it]\u001b[A\n",
      " 10%|█         | 40/400 [02:09<19:50,  3.31s/it]\u001b[A\n",
      " 10%|█         | 41/400 [02:12<18:56,  3.17s/it]\u001b[A\n",
      " 10%|█         | 42/400 [02:16<19:37,  3.29s/it]\u001b[A\n",
      " 11%|█         | 43/400 [02:18<18:55,  3.18s/it]\u001b[A\n",
      " 11%|█         | 44/400 [02:22<18:38,  3.14s/it]\u001b[A\n",
      " 11%|█▏        | 45/400 [02:25<19:23,  3.28s/it]\u001b[A\n",
      " 12%|█▏        | 46/400 [02:29<20:16,  3.44s/it]\u001b[A\n",
      " 12%|█▏        | 47/400 [02:32<19:28,  3.31s/it]\u001b[A\n",
      " 12%|█▏        | 48/400 [02:35<19:22,  3.30s/it]\u001b[A\n",
      " 12%|█▏        | 49/400 [02:38<19:14,  3.29s/it]\u001b[A\n",
      " 12%|█▎        | 50/400 [02:42<18:45,  3.22s/it]\u001b[A\n",
      " 13%|█▎        | 51/400 [02:45<18:39,  3.21s/it]\u001b[A\n",
      " 13%|█▎        | 52/400 [02:48<18:56,  3.27s/it]\u001b[A\n",
      " 13%|█▎        | 53/400 [02:51<18:32,  3.21s/it]\u001b[A\n",
      " 14%|█▎        | 54/400 [02:54<18:07,  3.14s/it]\u001b[A\n",
      " 14%|█▍        | 55/400 [02:57<17:45,  3.09s/it]\u001b[A\n",
      " 14%|█▍        | 56/400 [03:00<17:30,  3.05s/it]\u001b[A\n",
      " 14%|█▍        | 57/400 [03:04<18:22,  3.22s/it]\u001b[A\n",
      " 14%|█▍        | 58/400 [03:07<18:28,  3.24s/it]\u001b[A\n",
      " 15%|█▍        | 59/400 [03:10<18:46,  3.30s/it]\u001b[A\n",
      " 15%|█▌        | 60/400 [03:14<19:15,  3.40s/it]\u001b[A\n",
      " 15%|█▌        | 61/400 [03:17<18:18,  3.24s/it]\u001b[A\n",
      " 16%|█▌        | 62/400 [03:20<17:42,  3.14s/it]\u001b[A\n",
      " 16%|█▌        | 63/400 [03:23<17:13,  3.07s/it]\u001b[A\n",
      " 16%|█▌        | 64/400 [03:26<17:39,  3.15s/it]\u001b[A\n",
      " 16%|█▋        | 65/400 [03:29<17:43,  3.17s/it]\u001b[A\n",
      " 16%|█▋        | 66/400 [03:33<17:39,  3.17s/it]\u001b[A\n",
      " 17%|█▋        | 67/400 [03:35<17:18,  3.12s/it]\u001b[A\n",
      " 17%|█▋        | 68/400 [03:39<18:05,  3.27s/it]\u001b[A\n",
      " 17%|█▋        | 69/400 [03:42<17:27,  3.16s/it]\u001b[A\n",
      " 18%|█▊        | 70/400 [03:45<17:17,  3.14s/it]\u001b[A\n",
      " 18%|█▊        | 71/400 [03:48<17:24,  3.17s/it]\u001b[A\n",
      " 18%|█▊        | 72/400 [03:52<18:08,  3.32s/it]\u001b[A\n",
      " 18%|█▊        | 73/400 [03:55<17:09,  3.15s/it]\u001b[A\n",
      " 18%|█▊        | 74/400 [03:58<16:39,  3.07s/it]\u001b[A\n",
      " 19%|█▉        | 75/400 [04:01<16:38,  3.07s/it]\u001b[A\n",
      " 19%|█▉        | 76/400 [04:04<16:26,  3.05s/it]\u001b[A\n",
      " 19%|█▉        | 77/400 [04:07<16:12,  3.01s/it]\u001b[A\n",
      " 20%|█▉        | 78/400 [04:10<16:12,  3.02s/it]\u001b[A\n",
      " 20%|█▉        | 79/400 [04:14<17:46,  3.32s/it]\u001b[A\n",
      " 20%|██        | 80/400 [04:17<17:53,  3.35s/it]\u001b[A\n",
      " 20%|██        | 81/400 [04:20<16:56,  3.19s/it]\u001b[A\n",
      " 20%|██        | 82/400 [04:24<17:28,  3.30s/it]\u001b[A\n",
      " 21%|██        | 83/400 [04:26<16:39,  3.15s/it]\u001b[A\n",
      " 21%|██        | 84/400 [04:30<16:43,  3.18s/it]\u001b[A\n",
      " 21%|██▏       | 85/400 [04:32<16:02,  3.06s/it]\u001b[A\n",
      " 22%|██▏       | 86/400 [04:35<15:55,  3.04s/it]\u001b[A\n",
      " 22%|██▏       | 87/400 [04:38<15:51,  3.04s/it]\u001b[A\n",
      " 22%|██▏       | 88/400 [04:42<16:41,  3.21s/it]\u001b[A\n",
      " 22%|██▏       | 89/400 [04:45<16:37,  3.21s/it]\u001b[A\n",
      " 22%|██▎       | 90/400 [04:48<15:59,  3.09s/it]\u001b[A\n",
      " 23%|██▎       | 91/400 [04:52<17:11,  3.34s/it]\u001b[A\n",
      " 23%|██▎       | 92/400 [04:55<16:23,  3.19s/it]\u001b[A\n",
      " 23%|██▎       | 93/400 [04:58<16:28,  3.22s/it]\u001b[A\n",
      " 24%|██▎       | 94/400 [05:01<16:03,  3.15s/it]\u001b[A\n",
      " 24%|██▍       | 95/400 [05:04<16:22,  3.22s/it]\u001b[A\n",
      " 24%|██▍       | 96/400 [05:08<16:05,  3.18s/it]\u001b[A\n",
      " 24%|██▍       | 97/400 [05:11<16:19,  3.23s/it]\u001b[A\n",
      " 24%|██▍       | 98/400 [05:14<16:05,  3.20s/it]\u001b[A\n",
      " 25%|██▍       | 99/400 [05:18<17:13,  3.43s/it]\u001b[A\n",
      " 25%|██▌       | 100/400 [05:21<16:51,  3.37s/it]\u001b[A\n",
      " 25%|██▌       | 101/400 [05:24<16:13,  3.26s/it]\u001b[A\n",
      " 26%|██▌       | 102/400 [05:27<15:58,  3.21s/it]\u001b[A\n",
      " 26%|██▌       | 103/400 [05:30<15:35,  3.15s/it]\u001b[A\n",
      " 26%|██▌       | 104/400 [05:34<16:10,  3.28s/it]\u001b[A\n",
      " 26%|██▋       | 105/400 [05:37<15:45,  3.20s/it]\u001b[A\n",
      " 26%|██▋       | 106/400 [05:40<15:33,  3.17s/it]\u001b[A\n",
      " 27%|██▋       | 107/400 [05:43<15:38,  3.20s/it]\u001b[A\n",
      " 27%|██▋       | 108/400 [05:47<16:12,  3.33s/it]\u001b[A\n",
      " 27%|██▋       | 109/400 [05:50<15:25,  3.18s/it]\u001b[A\n",
      " 28%|██▊       | 110/400 [05:53<15:32,  3.22s/it]\u001b[A\n",
      " 28%|██▊       | 111/400 [05:57<15:55,  3.31s/it]\u001b[A\n",
      " 28%|██▊       | 112/400 [06:00<15:52,  3.31s/it]\u001b[A\n",
      " 28%|██▊       | 113/400 [06:03<15:13,  3.18s/it]\u001b[A\n",
      " 28%|██▊       | 114/400 [06:06<14:45,  3.10s/it]\u001b[A\n",
      " 29%|██▉       | 115/400 [06:09<14:29,  3.05s/it]\u001b[A\n",
      " 29%|██▉       | 116/400 [06:12<14:24,  3.05s/it]\u001b[A\n",
      " 29%|██▉       | 117/400 [06:15<14:14,  3.02s/it]\u001b[A\n",
      " 30%|██▉       | 118/400 [06:18<14:02,  2.99s/it]\u001b[A\n",
      " 30%|██▉       | 119/400 [06:20<13:46,  2.94s/it]\u001b[A\n",
      " 30%|███       | 120/400 [06:24<14:11,  3.04s/it]\u001b[A\n",
      " 30%|███       | 121/400 [06:27<15:00,  3.23s/it]\u001b[A\n",
      " 30%|███       | 122/400 [06:30<14:33,  3.14s/it]\u001b[A\n",
      " 31%|███       | 123/400 [06:34<15:15,  3.30s/it]\u001b[A\n",
      " 31%|███       | 124/400 [06:37<14:24,  3.13s/it]\u001b[A\n",
      " 31%|███▏      | 125/400 [06:39<13:50,  3.02s/it]\u001b[A\n",
      " 32%|███▏      | 126/400 [06:43<14:10,  3.10s/it]\u001b[A\n",
      " 32%|███▏      | 127/400 [06:46<14:21,  3.16s/it]\u001b[A\n",
      " 32%|███▏      | 128/400 [06:49<14:08,  3.12s/it]\u001b[A\n",
      " 32%|███▏      | 129/400 [06:52<13:51,  3.07s/it]\u001b[A\n",
      " 32%|███▎      | 130/400 [06:55<13:41,  3.04s/it]\u001b[A\n",
      " 33%|███▎      | 131/400 [06:58<13:34,  3.03s/it]\u001b[A\n",
      " 33%|███▎      | 132/400 [07:01<13:50,  3.10s/it]\u001b[A\n",
      " 33%|███▎      | 133/400 [07:05<14:10,  3.19s/it]\u001b[A\n",
      " 34%|███▎      | 134/400 [07:08<14:59,  3.38s/it]\u001b[A\n",
      " 34%|███▍      | 135/400 [07:11<14:16,  3.23s/it]\u001b[A\n",
      " 34%|███▍      | 136/400 [07:15<14:16,  3.25s/it]\u001b[A\n",
      " 34%|███▍      | 137/400 [07:18<13:57,  3.19s/it]\u001b[A\n",
      " 34%|███▍      | 138/400 [07:21<14:45,  3.38s/it]\u001b[A\n",
      " 35%|███▍      | 139/400 [07:25<15:07,  3.48s/it]\u001b[A\n",
      " 35%|███▌      | 140/400 [07:28<14:25,  3.33s/it]\u001b[A\n",
      " 35%|███▌      | 141/400 [07:31<14:14,  3.30s/it]\u001b[A\n",
      " 36%|███▌      | 142/400 [07:34<13:51,  3.22s/it]\u001b[A\n",
      " 36%|███▌      | 143/400 [07:38<13:52,  3.24s/it]\u001b[A\n",
      " 36%|███▌      | 144/400 [07:41<14:23,  3.37s/it]\u001b[A\n",
      " 36%|███▋      | 145/400 [07:44<13:59,  3.29s/it]\u001b[A\n",
      " 36%|███▋      | 146/400 [07:47<13:14,  3.13s/it]\u001b[A\n",
      " 37%|███▋      | 147/400 [07:50<12:53,  3.06s/it]\u001b[A\n",
      " 37%|███▋      | 148/400 [07:53<12:46,  3.04s/it]\u001b[A\n",
      " 37%|███▋      | 149/400 [07:56<13:06,  3.13s/it]\u001b[A\n",
      " 38%|███▊      | 150/400 [08:00<13:42,  3.29s/it]\u001b[A\n",
      " 38%|███▊      | 151/400 [08:03<12:51,  3.10s/it]\u001b[A\n",
      " 38%|███▊      | 152/400 [08:06<12:36,  3.05s/it]\u001b[A\n",
      " 38%|███▊      | 153/400 [08:09<13:10,  3.20s/it]\u001b[A\n",
      " 38%|███▊      | 154/400 [08:12<13:00,  3.17s/it]\u001b[A\n",
      " 39%|███▉      | 155/400 [08:16<12:59,  3.18s/it]\u001b[A\n",
      " 39%|███▉      | 156/400 [08:19<12:39,  3.11s/it]\u001b[A\n",
      " 39%|███▉      | 157/400 [08:22<12:28,  3.08s/it]\u001b[A\n",
      " 40%|███▉      | 158/400 [08:24<12:12,  3.03s/it]\u001b[A\n",
      " 40%|███▉      | 159/400 [08:28<12:25,  3.09s/it]\u001b[A\n",
      " 40%|████      | 160/400 [08:31<12:15,  3.06s/it]\u001b[A\n",
      " 40%|████      | 161/400 [08:34<13:00,  3.27s/it]\u001b[A\n",
      " 40%|████      | 162/400 [08:38<13:20,  3.36s/it]\u001b[A\n",
      " 41%|████      | 163/400 [08:41<12:44,  3.23s/it]\u001b[A\n",
      " 41%|████      | 164/400 [08:44<12:02,  3.06s/it]\u001b[A\n",
      " 41%|████▏     | 165/400 [08:47<12:20,  3.15s/it]\u001b[A\n",
      " 42%|████▏     | 166/400 [08:50<12:05,  3.10s/it]\u001b[A\n",
      " 42%|████▏     | 167/400 [08:53<12:00,  3.09s/it]\u001b[A\n",
      " 42%|████▏     | 168/400 [08:56<12:20,  3.19s/it]\u001b[A\n",
      " 42%|████▏     | 169/400 [09:00<12:11,  3.17s/it]\u001b[A\n",
      " 42%|████▎     | 170/400 [09:03<12:08,  3.17s/it]\u001b[A\n",
      " 43%|████▎     | 171/400 [09:06<11:51,  3.11s/it]\u001b[A\n",
      " 43%|████▎     | 172/400 [09:10<13:04,  3.44s/it]\u001b[A\n",
      " 43%|████▎     | 173/400 [09:13<12:30,  3.31s/it]\u001b[A\n",
      " 44%|████▎     | 174/400 [09:16<12:25,  3.30s/it]\u001b[A\n",
      " 44%|████▍     | 175/400 [09:19<12:02,  3.21s/it]\u001b[A\n",
      " 44%|████▍     | 176/400 [09:22<11:43,  3.14s/it]\u001b[A\n",
      " 44%|████▍     | 177/400 [09:26<12:06,  3.26s/it]\u001b[A\n",
      " 44%|████▍     | 178/400 [09:29<12:24,  3.35s/it]\u001b[A\n",
      " 45%|████▍     | 179/400 [09:32<12:07,  3.29s/it]\u001b[A\n",
      " 45%|████▌     | 180/400 [09:35<11:30,  3.14s/it]\u001b[A\n",
      " 45%|████▌     | 181/400 [09:38<11:27,  3.14s/it]\u001b[A\n",
      " 46%|████▌     | 182/400 [09:41<11:03,  3.04s/it]\u001b[A\n",
      " 46%|████▌     | 183/400 [09:45<11:45,  3.25s/it]\u001b[A\n",
      " 46%|████▌     | 184/400 [09:48<11:23,  3.16s/it]\u001b[A\n",
      " 46%|████▋     | 185/400 [09:51<11:10,  3.12s/it]\u001b[A\n",
      " 46%|████▋     | 186/400 [09:54<11:17,  3.17s/it]\u001b[A\n",
      " 47%|████▋     | 187/400 [09:57<11:19,  3.19s/it]\u001b[A\n",
      " 47%|████▋     | 188/400 [10:01<11:48,  3.34s/it]\u001b[A\n",
      " 47%|████▋     | 189/400 [10:05<11:54,  3.39s/it]\u001b[A\n",
      " 48%|████▊     | 190/400 [10:08<11:34,  3.31s/it]\u001b[A\n",
      " 48%|████▊     | 191/400 [10:11<11:58,  3.44s/it]\u001b[A\n",
      " 48%|████▊     | 192/400 [10:15<11:53,  3.43s/it]\u001b[A\n",
      " 48%|████▊     | 193/400 [10:18<11:25,  3.31s/it]\u001b[A\n",
      " 48%|████▊     | 194/400 [10:21<10:43,  3.12s/it]\u001b[A\n",
      " 49%|████▉     | 195/400 [10:23<10:21,  3.03s/it]\u001b[A\n",
      " 49%|████▉     | 196/400 [10:27<11:08,  3.28s/it]\u001b[A\n",
      " 49%|████▉     | 197/400 [10:30<10:28,  3.09s/it]\u001b[A\n",
      " 50%|████▉     | 198/400 [10:33<10:51,  3.22s/it]\u001b[A\n",
      " 50%|████▉     | 199/400 [10:37<10:54,  3.25s/it]\u001b[A\n",
      " 50%|█████     | 200/400 [10:41<11:38,  3.49s/it]\u001b[A\n",
      " 50%|█████     | 201/400 [10:44<11:33,  3.49s/it]\u001b[A\n",
      " 50%|█████     | 202/400 [10:47<10:49,  3.28s/it]\u001b[A\n",
      " 51%|█████     | 203/400 [10:51<10:59,  3.35s/it]\u001b[A\n",
      " 51%|█████     | 204/400 [10:54<11:26,  3.50s/it]\u001b[A\n",
      " 51%|█████▏    | 205/400 [10:58<11:15,  3.46s/it]\u001b[A\n",
      " 52%|█████▏    | 206/400 [11:01<10:40,  3.30s/it]\u001b[A\n",
      " 52%|█████▏    | 207/400 [11:04<10:15,  3.19s/it]\u001b[A\n",
      " 52%|█████▏    | 208/400 [11:07<09:54,  3.10s/it]\u001b[A\n",
      " 52%|█████▏    | 209/400 [11:10<09:46,  3.07s/it]\u001b[A\n",
      " 52%|█████▎    | 210/400 [11:12<09:23,  2.97s/it]\u001b[A\n",
      " 53%|█████▎    | 211/400 [11:16<09:35,  3.04s/it]\u001b[A\n",
      " 53%|█████▎    | 212/400 [11:19<09:35,  3.06s/it]\u001b[A\n",
      " 53%|█████▎    | 213/400 [11:22<09:26,  3.03s/it]\u001b[A\n",
      " 54%|█████▎    | 214/400 [11:24<09:13,  2.97s/it]\u001b[A\n",
      " 54%|█████▍    | 215/400 [11:27<09:12,  2.99s/it]\u001b[A\n",
      " 54%|█████▍    | 216/400 [11:30<09:06,  2.97s/it]\u001b[A\n",
      " 54%|█████▍    | 217/400 [11:34<09:54,  3.25s/it]\u001b[A\n",
      " 55%|█████▍    | 218/400 [11:37<09:45,  3.22s/it]\u001b[A\n",
      " 55%|█████▍    | 219/400 [11:41<10:07,  3.36s/it]\u001b[A\n",
      " 55%|█████▌    | 220/400 [11:44<09:50,  3.28s/it]\u001b[A\n",
      " 55%|█████▌    | 221/400 [11:47<09:20,  3.13s/it]\u001b[A\n",
      " 56%|█████▌    | 222/400 [11:50<09:10,  3.09s/it]\u001b[A\n",
      " 56%|█████▌    | 223/400 [11:53<09:16,  3.14s/it]\u001b[A\n",
      " 56%|█████▌    | 224/400 [11:56<08:54,  3.04s/it]\u001b[A\n",
      " 56%|█████▋    | 225/400 [11:59<08:59,  3.08s/it]\u001b[A\n",
      " 56%|█████▋    | 226/400 [12:02<08:57,  3.09s/it]\u001b[A\n",
      " 57%|█████▋    | 227/400 [12:06<09:02,  3.13s/it]\u001b[A\n",
      " 57%|█████▋    | 228/400 [12:09<08:51,  3.09s/it]\u001b[A\n",
      " 57%|█████▋    | 229/400 [12:13<09:33,  3.35s/it]\u001b[A\n",
      " 57%|█████▊    | 230/400 [12:16<09:11,  3.25s/it]\u001b[A\n",
      " 58%|█████▊    | 231/400 [12:19<09:10,  3.25s/it]\u001b[A\n",
      " 58%|█████▊    | 232/400 [12:22<09:02,  3.23s/it]\u001b[A\n",
      " 58%|█████▊    | 233/400 [12:26<09:21,  3.37s/it]\u001b[A\n",
      " 58%|█████▊    | 234/400 [12:29<09:07,  3.30s/it]\u001b[A\n",
      " 59%|█████▉    | 235/400 [12:32<09:02,  3.29s/it]\u001b[A\n",
      " 59%|█████▉    | 236/400 [12:35<08:42,  3.19s/it]\u001b[A\n",
      " 59%|█████▉    | 237/400 [12:38<08:37,  3.17s/it]\u001b[A\n",
      " 60%|█████▉    | 238/400 [12:41<08:31,  3.15s/it]\u001b[A\n",
      " 60%|█████▉    | 239/400 [12:45<08:36,  3.21s/it]\u001b[A\n",
      " 60%|██████    | 240/400 [12:48<08:58,  3.36s/it]\u001b[A\n",
      " 60%|██████    | 241/400 [12:52<08:51,  3.34s/it]\u001b[A\n",
      " 60%|██████    | 242/400 [12:56<09:20,  3.55s/it]\u001b[A\n",
      " 61%|██████    | 243/400 [12:59<08:54,  3.40s/it]\u001b[A\n",
      " 61%|██████    | 244/400 [13:02<08:29,  3.27s/it]\u001b[A\n",
      " 61%|██████▏   | 245/400 [13:05<08:08,  3.15s/it]\u001b[A\n",
      " 62%|██████▏   | 246/400 [13:08<08:20,  3.25s/it]\u001b[A\n",
      " 62%|██████▏   | 247/400 [13:11<08:02,  3.15s/it]\u001b[A\n",
      " 62%|██████▏   | 248/400 [13:14<07:56,  3.13s/it]\u001b[A\n",
      " 62%|██████▏   | 249/400 [13:18<08:17,  3.29s/it]\u001b[A\n",
      " 62%|██████▎   | 250/400 [13:21<07:54,  3.16s/it]\u001b[A\n",
      " 63%|██████▎   | 251/400 [13:24<08:14,  3.32s/it]\u001b[A\n",
      " 63%|██████▎   | 252/400 [13:27<08:04,  3.27s/it]\u001b[A\n",
      " 63%|██████▎   | 253/400 [13:30<07:37,  3.12s/it]\u001b[A\n",
      " 64%|██████▎   | 254/400 [13:34<07:48,  3.21s/it]\u001b[A\n",
      " 64%|██████▍   | 255/400 [13:36<07:27,  3.09s/it]\u001b[A\n",
      " 64%|██████▍   | 256/400 [13:39<07:02,  2.93s/it]\u001b[A\n",
      " 64%|██████▍   | 257/400 [13:42<07:03,  2.96s/it]\u001b[A\n",
      " 64%|██████▍   | 258/400 [13:45<06:57,  2.94s/it]\u001b[A\n",
      " 65%|██████▍   | 259/400 [13:49<07:36,  3.24s/it]\u001b[A\n",
      " 65%|██████▌   | 260/400 [13:52<07:23,  3.17s/it]\u001b[A\n",
      " 65%|██████▌   | 261/400 [13:55<07:23,  3.19s/it]\u001b[A\n",
      " 66%|██████▌   | 262/400 [13:59<07:34,  3.29s/it]\u001b[A\n",
      " 66%|██████▌   | 263/400 [14:01<07:11,  3.15s/it]\u001b[A\n",
      " 66%|██████▌   | 264/400 [14:04<07:01,  3.10s/it]\u001b[A\n",
      " 66%|██████▋   | 265/400 [14:07<06:52,  3.06s/it]\u001b[A\n",
      " 66%|██████▋   | 266/400 [14:11<06:58,  3.13s/it]\u001b[A\n",
      " 67%|██████▋   | 267/400 [14:14<06:57,  3.14s/it]\u001b[A\n",
      " 67%|██████▋   | 268/400 [14:17<06:48,  3.10s/it]\u001b[A\n",
      " 67%|██████▋   | 269/400 [14:20<06:54,  3.17s/it]\u001b[A\n",
      " 68%|██████▊   | 270/400 [14:23<06:58,  3.22s/it]\u001b[A\n",
      " 68%|██████▊   | 271/400 [14:27<07:13,  3.36s/it]\u001b[A\n",
      " 68%|██████▊   | 272/400 [14:30<07:01,  3.29s/it]\u001b[A\n",
      " 68%|██████▊   | 273/400 [14:34<07:25,  3.51s/it]\u001b[A\n",
      " 68%|██████▊   | 274/400 [14:37<06:58,  3.32s/it]\u001b[A\n",
      " 69%|██████▉   | 275/400 [14:41<06:57,  3.34s/it]\u001b[A\n",
      " 69%|██████▉   | 276/400 [14:44<07:04,  3.42s/it]\u001b[A\n",
      " 69%|██████▉   | 277/400 [14:47<06:51,  3.34s/it]\u001b[A\n",
      " 70%|██████▉   | 278/400 [14:50<06:40,  3.29s/it]\u001b[A\n",
      " 70%|██████▉   | 279/400 [14:54<06:34,  3.26s/it]\u001b[A\n",
      " 70%|███████   | 280/400 [14:57<06:24,  3.20s/it]\u001b[A\n",
      " 70%|███████   | 281/400 [15:00<06:33,  3.31s/it]\u001b[A\n",
      " 70%|███████   | 282/400 [15:04<06:32,  3.33s/it]\u001b[A\n",
      " 71%|███████   | 283/400 [15:07<06:44,  3.45s/it]\u001b[A\n",
      " 71%|███████   | 284/400 [15:10<06:20,  3.28s/it]\u001b[A\n",
      " 71%|███████▏  | 285/400 [15:13<06:11,  3.23s/it]\u001b[A\n",
      " 72%|███████▏  | 286/400 [15:17<06:20,  3.33s/it]\u001b[A\n",
      " 72%|███████▏  | 287/400 [15:20<06:07,  3.25s/it]\u001b[A\n",
      " 72%|███████▏  | 288/400 [15:24<06:13,  3.34s/it]\u001b[A\n",
      " 72%|███████▏  | 289/400 [15:27<06:10,  3.34s/it]\u001b[A\n",
      " 72%|███████▎  | 290/400 [15:30<06:11,  3.37s/it]\u001b[A\n",
      " 73%|███████▎  | 291/400 [15:33<05:57,  3.28s/it]\u001b[A\n",
      " 73%|███████▎  | 292/400 [15:37<05:54,  3.28s/it]\u001b[A\n",
      " 73%|███████▎  | 293/400 [15:40<05:48,  3.26s/it]\u001b[A\n",
      " 74%|███████▎  | 294/400 [15:44<05:59,  3.39s/it]\u001b[A\n",
      " 74%|███████▍  | 295/400 [15:47<05:42,  3.26s/it]\u001b[A\n",
      " 74%|███████▍  | 296/400 [15:50<05:28,  3.16s/it]\u001b[A\n",
      " 74%|███████▍  | 297/400 [15:52<05:16,  3.07s/it]\u001b[A\n",
      " 74%|███████▍  | 298/400 [15:55<05:09,  3.04s/it]\u001b[A\n",
      " 75%|███████▍  | 299/400 [16:00<05:40,  3.37s/it]\u001b[A\n",
      " 75%|███████▌  | 300/400 [16:02<05:23,  3.23s/it]\u001b[A\n",
      " 75%|███████▌  | 301/400 [16:05<05:10,  3.14s/it]\u001b[A\n",
      " 76%|███████▌  | 302/400 [16:09<05:23,  3.30s/it]\u001b[A\n",
      " 76%|███████▌  | 303/400 [16:12<05:08,  3.18s/it]\u001b[A\n",
      " 76%|███████▌  | 304/400 [16:15<04:55,  3.08s/it]\u001b[A\n",
      " 76%|███████▋  | 305/400 [16:18<04:47,  3.03s/it]\u001b[A\n",
      " 76%|███████▋  | 306/400 [16:21<04:42,  3.00s/it]\u001b[A\n",
      " 77%|███████▋  | 307/400 [16:24<04:47,  3.09s/it]\u001b[A\n",
      " 77%|███████▋  | 308/400 [16:27<04:46,  3.11s/it]\u001b[A\n",
      " 77%|███████▋  | 309/400 [16:30<04:37,  3.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 310/400 [16:33<04:33,  3.04s/it]\u001b[A\n",
      " 78%|███████▊  | 311/400 [16:36<04:28,  3.02s/it]\u001b[A\n",
      " 78%|███████▊  | 312/400 [16:39<04:29,  3.06s/it]\u001b[A\n",
      " 78%|███████▊  | 313/400 [16:43<04:39,  3.22s/it]\u001b[A\n",
      " 78%|███████▊  | 314/400 [16:46<04:29,  3.13s/it]\u001b[A\n",
      " 79%|███████▉  | 315/400 [16:49<04:35,  3.24s/it]\u001b[A\n",
      " 79%|███████▉  | 316/400 [16:52<04:28,  3.19s/it]\u001b[A\n",
      " 79%|███████▉  | 317/400 [16:55<04:14,  3.07s/it]\u001b[A\n",
      " 80%|███████▉  | 318/400 [16:58<04:10,  3.06s/it]\u001b[A\n",
      " 80%|███████▉  | 319/400 [17:01<04:07,  3.06s/it]\u001b[A\n",
      " 80%|████████  | 320/400 [17:04<03:59,  3.00s/it]\u001b[A\n",
      " 80%|████████  | 321/400 [17:07<04:04,  3.10s/it]\u001b[A\n",
      " 80%|████████  | 322/400 [17:11<04:07,  3.17s/it]\u001b[A\n",
      " 81%|████████  | 323/400 [17:14<03:58,  3.10s/it]\u001b[A\n",
      " 81%|████████  | 324/400 [17:17<03:54,  3.09s/it]\u001b[A\n",
      " 81%|████████▏ | 325/400 [17:20<03:59,  3.19s/it]\u001b[A\n",
      " 82%|████████▏ | 326/400 [17:23<03:52,  3.14s/it]\u001b[A\n",
      " 82%|████████▏ | 327/400 [17:26<03:39,  3.01s/it]\u001b[A\n",
      " 82%|████████▏ | 328/400 [17:29<03:34,  2.98s/it]\u001b[A\n",
      " 82%|████████▏ | 329/400 [17:32<03:32,  3.00s/it]\u001b[A\n",
      " 82%|████████▎ | 330/400 [17:35<03:32,  3.03s/it]\u001b[A\n",
      " 83%|████████▎ | 331/400 [17:38<03:36,  3.13s/it]\u001b[A\n",
      " 83%|████████▎ | 332/400 [17:41<03:27,  3.05s/it]\u001b[A\n",
      " 83%|████████▎ | 333/400 [17:44<03:24,  3.05s/it]\u001b[A\n",
      " 84%|████████▎ | 334/400 [17:47<03:18,  3.00s/it]\u001b[A\n",
      " 84%|████████▍ | 335/400 [17:50<03:20,  3.08s/it]\u001b[A\n",
      " 84%|████████▍ | 336/400 [17:53<03:17,  3.08s/it]\u001b[A\n",
      " 84%|████████▍ | 337/400 [17:57<03:24,  3.24s/it]\u001b[A\n",
      " 84%|████████▍ | 338/400 [18:00<03:10,  3.07s/it]\u001b[A\n",
      " 85%|████████▍ | 339/400 [18:03<03:04,  3.03s/it]\u001b[A\n",
      " 85%|████████▌ | 340/400 [18:05<02:58,  2.98s/it]\u001b[A\n",
      " 85%|████████▌ | 341/400 [18:09<02:59,  3.04s/it]\u001b[A\n",
      " 86%|████████▌ | 342/400 [18:11<02:53,  2.99s/it]\u001b[A\n",
      " 86%|████████▌ | 343/400 [18:15<02:53,  3.04s/it]\u001b[A\n",
      " 86%|████████▌ | 344/400 [18:18<02:52,  3.08s/it]\u001b[A\n",
      " 86%|████████▋ | 345/400 [18:21<02:51,  3.13s/it]\u001b[A\n",
      " 86%|████████▋ | 346/400 [18:24<02:54,  3.23s/it]\u001b[A\n",
      " 87%|████████▋ | 347/400 [18:28<02:47,  3.16s/it]\u001b[A\n",
      " 87%|████████▋ | 348/400 [18:31<02:44,  3.17s/it]\u001b[A\n",
      " 87%|████████▋ | 349/400 [18:34<02:41,  3.17s/it]\u001b[A\n",
      " 88%|████████▊ | 350/400 [18:37<02:39,  3.18s/it]\u001b[A\n",
      " 88%|████████▊ | 351/400 [18:40<02:36,  3.20s/it]\u001b[A\n",
      " 88%|████████▊ | 352/400 [18:43<02:28,  3.10s/it]\u001b[A\n",
      " 88%|████████▊ | 353/400 [18:46<02:26,  3.12s/it]\u001b[A\n",
      " 88%|████████▊ | 354/400 [18:49<02:20,  3.06s/it]\u001b[A\n",
      " 89%|████████▉ | 355/400 [18:52<02:13,  2.96s/it]\u001b[A\n",
      " 89%|████████▉ | 356/400 [18:56<02:18,  3.15s/it]\u001b[A\n",
      " 89%|████████▉ | 357/400 [18:59<02:14,  3.14s/it]\u001b[A\n",
      " 90%|████████▉ | 358/400 [19:02<02:08,  3.06s/it]\u001b[A\n",
      " 90%|████████▉ | 359/400 [19:05<02:06,  3.10s/it]\u001b[A\n",
      " 90%|█████████ | 360/400 [19:08<02:10,  3.26s/it]\u001b[A\n",
      " 90%|█████████ | 361/400 [19:11<02:03,  3.17s/it]\u001b[A\n",
      " 90%|█████████ | 362/400 [19:15<02:02,  3.22s/it]\u001b[A\n",
      " 91%|█████████ | 363/400 [19:17<01:54,  3.08s/it]\u001b[A\n",
      " 91%|█████████ | 364/400 [19:21<01:50,  3.07s/it]\u001b[A\n",
      " 91%|█████████▏| 365/400 [19:24<01:50,  3.14s/it]\u001b[A\n",
      " 92%|█████████▏| 366/400 [19:27<01:45,  3.12s/it]\u001b[A\n",
      " 92%|█████████▏| 367/400 [19:30<01:42,  3.09s/it]\u001b[A\n",
      " 92%|█████████▏| 368/400 [19:33<01:40,  3.14s/it]\u001b[A\n",
      " 92%|█████████▏| 369/400 [19:36<01:35,  3.07s/it]\u001b[A\n",
      " 92%|█████████▎| 370/400 [19:39<01:29,  2.97s/it]\u001b[A\n",
      " 93%|█████████▎| 371/400 [19:42<01:28,  3.06s/it]\u001b[A\n",
      " 93%|█████████▎| 372/400 [19:45<01:26,  3.09s/it]\u001b[A\n",
      " 93%|█████████▎| 373/400 [19:48<01:22,  3.06s/it]\u001b[A\n",
      " 94%|█████████▎| 374/400 [19:51<01:18,  3.00s/it]\u001b[A\n",
      " 94%|█████████▍| 375/400 [19:54<01:16,  3.05s/it]\u001b[A\n",
      " 94%|█████████▍| 376/400 [19:57<01:11,  3.00s/it]\u001b[A\n",
      " 94%|█████████▍| 377/400 [20:00<01:10,  3.07s/it]\u001b[A\n",
      " 94%|█████████▍| 378/400 [20:04<01:08,  3.13s/it]\u001b[A\n",
      " 95%|█████████▍| 379/400 [20:07<01:09,  3.29s/it]\u001b[A\n",
      " 95%|█████████▌| 380/400 [20:11<01:07,  3.35s/it]\u001b[A\n",
      " 95%|█████████▌| 381/400 [20:14<01:01,  3.25s/it]\u001b[A\n",
      " 96%|█████████▌| 382/400 [20:17<00:56,  3.11s/it]\u001b[A\n",
      " 96%|█████████▌| 383/400 [20:20<00:55,  3.26s/it]\u001b[A\n",
      " 96%|█████████▌| 384/400 [20:23<00:50,  3.18s/it]\u001b[A\n",
      " 96%|█████████▋| 385/400 [20:26<00:45,  3.04s/it]\u001b[A\n",
      " 96%|█████████▋| 386/400 [20:29<00:41,  2.94s/it]\u001b[A\n",
      " 97%|█████████▋| 387/400 [20:31<00:37,  2.92s/it]\u001b[A\n",
      " 97%|█████████▋| 388/400 [20:34<00:34,  2.89s/it]\u001b[A\n",
      " 97%|█████████▋| 389/400 [20:37<00:31,  2.85s/it]\u001b[A\n",
      " 98%|█████████▊| 390/400 [20:40<00:27,  2.78s/it]\u001b[A\n",
      " 98%|█████████▊| 391/400 [20:43<00:27,  3.02s/it]\u001b[A\n",
      " 98%|█████████▊| 392/400 [20:47<00:25,  3.17s/it]\u001b[A\n",
      " 98%|█████████▊| 393/400 [20:50<00:22,  3.26s/it]\u001b[A\n",
      " 98%|█████████▊| 394/400 [20:53<00:18,  3.10s/it]\u001b[A\n",
      " 99%|█████████▉| 395/400 [20:56<00:14,  2.96s/it]\u001b[A\n",
      " 99%|█████████▉| 396/400 [20:58<00:11,  2.93s/it]\u001b[A\n",
      " 99%|█████████▉| 397/400 [21:01<00:08,  2.89s/it]\u001b[A\n",
      "100%|█████████▉| 398/400 [21:04<00:05,  2.97s/it]\u001b[A\n",
      "100%|█████████▉| 399/400 [21:08<00:03,  3.04s/it]\u001b[A\n",
      "100%|██████████| 400/400 [21:11<00:00,  3.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1271.5324783325195\n"
     ]
    }
   ],
   "source": [
    "# Define face detection pipeline\n",
    "detection_pipeline = DetectionPipeline(detector=mtcnn, batch_size=60, resize=None, n_frames=45)\n",
    "\n",
    "# Get all test videos\n",
    "filenames = glob.glob('data/train_sample_videos/*.mp4')\n",
    "metadata = pd.read_json('data/train_sample_videos/metadata.json').T\n",
    "\n",
    "X1 = []\n",
    "X1_encoded = []\n",
    "Y1 = []\n",
    "X2 = []\n",
    "X2_encoded = []\n",
    "Y2 = []\n",
    "X3 = []\n",
    "X3_encoded = []\n",
    "Y3 = []\n",
    "start = time.time()\n",
    "n_processed = 0\n",
    "with torch.no_grad():\n",
    "    for i, filename in tqdm(enumerate(filenames), total=len(filenames)):\n",
    "        try:\n",
    "            # Load frames and find faces\n",
    "            faces = detection_pipeline(filename)\n",
    "            y = int((metadata.label['data/train_sample_videos/' + metadata.index == filename] == 'REAL') * 1)\n",
    "            n_faces = [x.shape[0] if x is not None else 0 for x in faces ]\n",
    "            faces = [x for x in faces if x is not None]\n",
    "            if n_faces.count(3) >= 30:\n",
    "                f_faces = [x for x in faces if x.shape[0] == 3]\n",
    "                f_faces = [f_faces[i] for i in np.linspace(0, len(f_faces)-1, 30).astype(int)]\n",
    "                X3.append(f_faces)\n",
    "                X3_encoded.append(process_faces(f_faces, resnet))\n",
    "                Y3.append(y)\n",
    "            elif n_faces.count(2) >= 30:\n",
    "                f_faces = [x for x in faces if x.shape[0] == 2]\n",
    "                f_faces = [f_faces[i] for i in np.linspace(0, len(f_faces)-1, 30).astype(int)]\n",
    "                X2.append(f_faces)\n",
    "                X2_encoded.append(process_faces(f_faces, resnet))\n",
    "                Y2.append(y)\n",
    "            elif n_faces.count(1) >= 30:\n",
    "                f_faces = [x for x in faces if x.shape[0] == 1]\n",
    "                f_faces = [f_faces[i] for i in np.linspace(0, len(f_faces)-1, 30).astype(int)]\n",
    "                X1.append(f_faces)\n",
    "                X1_encoded.append(process_faces(f_faces, resnet))\n",
    "                Y1.append(y)\n",
    "            #             # 1 faces ----------\n",
    "#             if [x.shape[0] for x in faces if x is not None] == [1] * 30:\n",
    "#                 # Calculate embeddings\n",
    "#                 X1.append(faces)\n",
    "#                 X1_encoded.append(process_faces(faces, resnet))\n",
    "#                 Y1.append(y)\n",
    "#             # 2 faces ----------   \n",
    "#             if [x.shape[0] for x in faces if x is not None] == [2] * 30:\n",
    "#                 # Calculate embeddings\n",
    "#                 X2.append(faces)\n",
    "#                 X2_encoded.append(process_faces(faces, resnet))\n",
    "#                 Y2.append(y)\n",
    "#             # 3 faces ----------   \n",
    "#             if [x.shape[0] for x in faces if x is not None] == [3] * 30:\n",
    "#                 # Calculate embeddings\n",
    "#                 X3.append(faces)\n",
    "#                 X3_encoded.append(process_faces(faces, resnet))\n",
    "#                 Y3.append(y)\n",
    "        except KeyboardInterrupt:\n",
    "            print('\\nStopped.')\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        n_processed += len(faces)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X2_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X1_encoded, 'data_processed/sample_train_faces_encoded_1face.pt')\n",
    "torch.save(Y1, 'data_processed/sample_train_faces_encoded_1face.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This GPU processes even folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_0/*.mp4 | 1334 files\n",
      "Frames per second (load+detect+embed): 0.00974\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [1:17:09<30:51:36, 4629.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_2/*.mp4 | 1748 files\n",
      "Frames per second (load+detect+embed): 0.00766\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [2:55:11<31:58:33, 5004.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_4/*.mp4 | 1701 files\n",
      "Frames per second (load+detect+embed): 0.00689\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [4:44:14<33:24:22, 5466.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_6/*.mp4 | 3464 files\n",
      "Frames per second (load+detect+embed): 0.00553\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [7:00:08<36:35:28, 6272.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_8/*.mp4 | 1816 files\n",
      "Frames per second (load+detect+embed): 0.00579\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [9:09:56<37:22:27, 6727.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_10/*.mp4 | 3192 files\n",
      "Frames per second (load+detect+embed): 0.00584\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [11:19:13<37:08:05, 7036.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_12/*.mp4 | 2225 files\n",
      "Frames per second (load+detect+embed): 0.00609\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [13:23:01<35:46:10, 7153.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_14/*.mp4 | 2464 files\n",
      "Frames per second (load+detect+embed): 0.00574\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [15:34:24<34:48:50, 7372.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_16/*.mp4 | 2061 files\n",
      "Frames per second (load+detect+embed): 0.00702\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [17:21:57<31:32:27, 7096.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_18/*.mp4 | 2683 files\n",
      "Frames per second (load+detect+embed): 0.00525\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [19:45:29<31:27:49, 7551.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_20/*.mp4 | 2154 files\n",
      "Frames per second (load+detect+embed): 0.00628\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [21:45:34<28:57:41, 7447.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_22/*.mp4 | 2409 files\n",
      "Frames per second (load+detect+embed): 0.00576\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [23:56:21<27:19:33, 7567.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_24/*.mp4 | 2786 files\n",
      "Frames per second (load+detect+embed): 0.00509\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [26:24:19<26:32:07, 7960.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_26/*.mp4 | 2433 files\n",
      "Frames per second (load+detect+embed): 0.00611\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [28:27:22<23:47:41, 7787.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_28/*.mp4 | 2085 files\n",
      "Frames per second (load+detect+embed): 0.00673\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 15/25 [30:19:00<20:43:24, 7460.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_30/*.mp4 | 2236 files\n",
      "Frames per second (load+detect+embed): 0.00637\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 16/25 [32:16:55<18:21:42, 7344.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_32/*.mp4 | 2356 files\n",
      "Frames per second (load+detect+embed): 0.00634\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 17/25 [34:15:26<16:09:58, 7274.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_34/*.mp4 | 2658 files\n",
      "could not broadcast input array from shape (0,5) into shape (0)\n",
      "could not broadcast input array from shape (0,5) into shape (0)\n",
      "could not broadcast input array from shape (0,5) into shape (0)\n",
      "could not broadcast input array from shape (0,5) into shape (0)\n",
      "could not broadcast input array from shape (0,5) into shape (0)\n",
      "could not broadcast input array from shape (0,5) into shape (0)\n",
      "Frames per second (load+detect+embed): 0.00543\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 18/25 [36:33:53<14:44:49, 7584.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_36/*.mp4 | 2339 files\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 10.78 GiB already allocated; 3.92 GiB free; 10.79 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 10.78 GiB already allocated; 433.19 MiB free; 14.29 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.79 GiB already allocated; 4.59 GiB free; 10.12 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.79 GiB already allocated; 4.59 GiB free; 10.12 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.79 GiB already allocated; 4.59 GiB free; 10.12 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.79 GiB already allocated; 4.59 GiB free; 10.12 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.79 GiB already allocated; 4.59 GiB free; 10.12 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.79 GiB already allocated; 4.59 GiB free; 10.13 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.59 GiB free; 10.13 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.58 GiB free; 10.13 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.58 GiB free; 10.13 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.58 GiB free; 10.13 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.58 GiB free; 10.13 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.58 GiB free; 10.14 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.80 GiB already allocated; 4.58 GiB free; 10.14 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.81 GiB already allocated; 4.58 GiB free; 10.14 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.81 GiB already allocated; 4.57 GiB free; 10.14 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.81 GiB already allocated; 4.57 GiB free; 10.14 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.81 GiB already allocated; 4.57 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.81 GiB already allocated; 4.57 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.57 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.15 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.16 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.82 GiB already allocated; 4.56 GiB free; 10.16 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.56 GiB free; 10.16 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.55 GiB free; 10.16 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.55 GiB free; 10.16 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.55 GiB free; 10.16 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.55 GiB free; 10.17 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.55 GiB free; 10.17 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.83 GiB already allocated; 4.55 GiB free; 10.17 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.84 GiB already allocated; 4.54 GiB free; 10.17 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.84 GiB already allocated; 4.54 GiB free; 10.18 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.84 GiB already allocated; 4.54 GiB free; 10.18 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.85 GiB already allocated; 4.54 GiB free; 10.18 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.85 GiB already allocated; 4.54 GiB free; 10.18 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.85 GiB already allocated; 4.53 GiB free; 10.18 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.85 GiB already allocated; 4.53 GiB free; 10.18 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.85 GiB already allocated; 4.53 GiB free; 10.19 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.85 GiB already allocated; 4.53 GiB free; 10.19 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.86 GiB already allocated; 4.53 GiB free; 10.19 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.86 GiB already allocated; 4.52 GiB free; 10.19 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.86 GiB already allocated; 4.52 GiB free; 10.19 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.86 GiB already allocated; 4.52 GiB free; 10.20 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.20 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.20 GiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.87 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.51 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.21 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.88 GiB already allocated; 4.50 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.89 GiB already allocated; 4.50 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.89 GiB already allocated; 4.49 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.89 GiB already allocated; 4.49 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.89 GiB already allocated; 4.49 GiB free; 10.22 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.89 GiB already allocated; 4.49 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.89 GiB already allocated; 4.49 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.90 GiB already allocated; 4.49 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.90 GiB already allocated; 4.48 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.90 GiB already allocated; 4.48 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.90 GiB already allocated; 4.48 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "CUDA out of memory. Tried to allocate 5.00 GiB (GPU 1; 15.78 GiB total capacity; 5.90 GiB already allocated; 4.48 GiB free; 10.23 GiB reserved in total by PyTorch)\n",
      "Frames per second (load+detect+embed): 0.0061\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 19/25 [38:37:08<12:32:45, 7527.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_38/*.mp4 | 2477 files\n",
      "Frames per second (load+detect+embed): 0.00555\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 20/25 [40:52:30<10:42:09, 7705.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_40/*.mp4 | 2420 files\n",
      "Frames per second (load+detect+embed): 0.00591\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 21/25 [42:59:36<8:32:07, 7681.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_42/*.mp4 | 2384 files\n",
      "Frames per second (load+detect+embed): 0.00584\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 22/25 [45:08:08<6:24:33, 7691.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_44/*.mp4 | 2665 files\n",
      "Frames per second (load+detect+embed): 0.00559\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 23/25 [47:22:32<4:20:05, 7802.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_46/*.mp4 | 2202 files\n",
      "Frames per second (load+detect+embed): 0.00641\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 24/25 [49:19:49<2:06:13, 7573.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/dfdc_train_part_48/*.mp4 | 2463 files\n",
      "Frames per second (load+detect+embed): 0.00582\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [51:28:47<00:00, 7622.42s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Define face detection pipeline\n",
    "detection_pipeline = DetectionPipeline(detector=mtcnn, batch_size=60, resize=None, n_frames=45)\n",
    "start = time.time()\n",
    "n_processed = 0\n",
    "with torch.no_grad():\n",
    "    for f in tqdm(np.arange(0, 49, 2), total = 25):\n",
    "        # Get all videos\n",
    "        filenames = glob.glob('data/dfdc_train_part_' + str(f) + '/*.mp4')\n",
    "        metadata = pd.read_json('data/dfdc_train_part_' + str(f) + '/metadata.json').T\n",
    "        print('data/dfdc_train_part_' + str(f) + '/*.mp4 | '+ str(len(filenames)) + ' files')\n",
    "        X1 = []\n",
    "        X1_encoded = []\n",
    "        Y1 = []\n",
    "        X2 = []\n",
    "        X2_encoded = []\n",
    "        Y2 = []\n",
    "        X3 = []\n",
    "        X3_encoded = []\n",
    "        Y3 = []\n",
    "        start = time.time()\n",
    "        n_processed = 0\n",
    "        for i, filename in enumerate(filenames):\n",
    "            try:\n",
    "                # Load frames and find faces\n",
    "                faces = detection_pipeline(filename)\n",
    "                y = int((metadata.label['data/dfdc_train_part_' + str(f) + '/' + metadata.index == filename] == 'REAL') * 1)\n",
    "                n_faces = [x.shape[0] if x is not None else 0 for x in faces ]\n",
    "                faces = [x for x in faces if x is not None]\n",
    "                if n_faces.count(3) >= 30:\n",
    "                    f_faces = [x for x in faces if x.shape[0] == 3]\n",
    "                    f_faces = [f_faces[i] for i in np.linspace(0, len(f_faces)-1, 30).astype(int)]\n",
    "                    X3.append(f_faces)\n",
    "                    X3_encoded.append(process_faces(f_faces, resnet))\n",
    "                    Y3.append(y)\n",
    "                elif n_faces.count(2) >= 30:\n",
    "                    f_faces = [x for x in faces if x.shape[0] == 2]\n",
    "                    f_faces = [f_faces[i] for i in np.linspace(0, len(f_faces)-1, 30).astype(int)]\n",
    "                    X2.append(f_faces)\n",
    "                    X2_encoded.append(process_faces(f_faces, resnet))\n",
    "                    Y2.append(y)\n",
    "                elif n_faces.count(1) >= 30:\n",
    "                    f_faces = [x for x in faces if x.shape[0] == 1]\n",
    "                    f_faces = [f_faces[i] for i in np.linspace(0, len(f_faces)-1, 30).astype(int)]\n",
    "                    X1.append(f_faces)\n",
    "                    X1_encoded.append(process_faces(f_faces, resnet))\n",
    "                    Y1.append(y)\n",
    "            except KeyboardInterrupt:\n",
    "                print('\\nStopped.')\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        n_processed += len(faces)\n",
    "        print(f'Frames per second (load+detect+embed): {n_processed / (time.time() - start):6.3}\\r', end='')\n",
    "        torch.save(X1_encoded, 'data_processed/1face_X_part' + str(f) + '.pt')\n",
    "        torch.save(Y1, 'data_processed/1face_Y_part' + str(f) + '.pt')\n",
    "        torch.save(X2_encoded, 'data_processed/2face_X_part' + str(f) + '.pt')\n",
    "        torch.save(Y2, 'data_processed/2face_Y_part' + str(f) + '.pt')\n",
    "        torch.save(X3_encoded, 'data_processed/3face_X_part' + str(f) + '.pt')\n",
    "        torch.save(Y3, 'data_processed/3face_Y_part' + str(f) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
